{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Our Audio Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Audio Files, Train, Test, Validation Sets, and Waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from google.cloud import storage\n",
    "\n",
    "# Set up Google Cloud credentials and initialize the client\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'aphasia-chatter-5a70166fc2f1.json'\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket('speech-sit-bucket')  # Replace with your bucket name\n",
    "\n",
    "# Define GCS directory and local download directory\n",
    "directory_prefix = 'audio/'  # GCS directory prefix\n",
    "download_directory = 'samples/audio'  # Local directory path\n",
    "\n",
    "# Check if the local directory exists\n",
    "if not os.path.exists(download_directory):\n",
    "    # If directory doesn't exist, create it\n",
    "    os.makedirs(download_directory)\n",
    "\n",
    "    # List all blobs (files) in the specified GCS directory\n",
    "    audios = bucket.list_blobs(prefix=directory_prefix)\n",
    "\n",
    "    # Initialize tqdm, but set the total to len(audio_file_set), the actual number of files to download\n",
    "    progress_bar = tqdm(total=14159, desc=\"Downloading Files\", unit=\" files\", leave=False)\n",
    "    for index, audio in enumerate(audios):\n",
    "        if index != 0:\n",
    "            audio_file_name = os.path.basename(audio.name)\n",
    "            local_file_path = os.path.join(download_directory, audio_file_name)\n",
    "            audio.download_to_filename(local_file_path)\n",
    "            progress_bar.update(1)\n",
    "    progress_bar.close()\n",
    "else:\n",
    "    # If the directory exists, read files from local storage\n",
    "    print(\"Reading files from the local directory...\")\n",
    "    files = sorted(os.listdir(download_directory))\n",
    "    print(f\"Loaded {len(files)} files from local directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from google.cloud import storage\n",
    "\n",
    "# Set up Google Cloud credentials and initialize the client\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'aphasia-chatter-5a70166fc2f1.json'\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket('speech-sit-bucket')  # Replace with your bucket name\n",
    "\n",
    "# Define GCS directory and local download directory\n",
    "directory_prefix = 'transcripts/'  # GCS directory prefix\n",
    "download_directory = 'samples/transcripts'  # Local directory path\n",
    "\n",
    "# Check if the local directory exists\n",
    "if not os.path.exists(download_directory):\n",
    "    # If directory doesn't exist, create it\n",
    "    os.makedirs(download_directory)\n",
    "\n",
    "    # List all blobs (files) in the specified GCS directory\n",
    "    audios = bucket.list_blobs(prefix=directory_prefix)\n",
    "\n",
    "    # Initialize tqdm, but set the total to len(audio_file_set), the actual number of files to download\n",
    "    progress_bar = tqdm(total=3, desc=\"Downloading Gold Dataset\", unit=\" files\", leave=False)\n",
    "    for index, audio in enumerate(audios):\n",
    "        audio_file_name = os.path.basename(audio.name)\n",
    "        local_file_path = os.path.join(download_directory, audio_file_name)\n",
    "        audio.download_to_filename(local_file_path)\n",
    "        progress_bar.update(1)\n",
    "    progress_bar.close()\n",
    "else:\n",
    "    # If the directory exists, read files from local storage\n",
    "    print(\"Reading files from the local directory...\")\n",
    "    files = sorted(os.listdir(download_directory))\n",
    "    print(f\"Loaded {len(files)} files from local directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from google.cloud import storage\n",
    "\n",
    "# Set up Google Cloud credentials and initialize the client\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'aphasia-chatter-5a70166fc2f1.json'\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket('speech-sit-bucket')  # Replace with your bucket name\n",
    "\n",
    "# Define GCS directory and local download directory\n",
    "directory_prefix = 'waveform/'  # GCS directory prefix\n",
    "download_directory = 'samples/waveform'  # Local directory path\n",
    "\n",
    "# Check if the local directory exists\n",
    "if not os.path.exists(download_directory):\n",
    "    # If directory doesn't exist, create it\n",
    "    os.makedirs(download_directory)\n",
    "\n",
    "    # List all blobs (files) in the specified GCS directory\n",
    "    audios = bucket.list_blobs(prefix=directory_prefix)\n",
    "\n",
    "    # Initialize tqdm, but set the total to len(audio_file_set), the actual number of files to download\n",
    "    progress_bar = tqdm(total=14159, desc=\"Downloading Files\", unit=\" files\", leave=False)\n",
    "    for index, audio in enumerate(audios):\n",
    "        if index != 0:\n",
    "            audio_file_name = os.path.basename(audio.name)\n",
    "            local_file_path = os.path.join(download_directory, audio_file_name)\n",
    "            audio.download_to_filename(local_file_path)\n",
    "            progress_bar.update(1)\n",
    "    progress_bar.close()\n",
    "else:\n",
    "    # If the directory exists, read files from local storage\n",
    "    print(\"Reading files from the local directory...\")\n",
    "    files = sorted(os.listdir(download_directory))\n",
    "    print(f\"Loaded {len(files)} files from local directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Total Audio Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('samples/transcripts/train_set.csv')\n",
    "val_set = pd.read_csv('samples/transcripts/val_set.csv')\n",
    "test_set = pd.read_csv('samples/transcripts/test_set.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9422 entries, 0 to 9421\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   patient          9422 non-null   object\n",
      " 1   path             9422 non-null   object\n",
      " 2   audio_base_path  9422 non-null   object\n",
      " 3   gold_transcript  9422 non-null   object\n",
      " 4   waveform_path    9422 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 368.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2047 entries, 0 to 2046\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   patient          2047 non-null   object\n",
      " 1   path             2047 non-null   object\n",
      " 2   audio_base_path  2047 non-null   object\n",
      " 3   gold_transcript  2047 non-null   object\n",
      " 4   waveform_path    2047 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 80.1+ KB\n"
     ]
    }
   ],
   "source": [
    "val_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2211 entries, 0 to 2210\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   patient          2211 non-null   object\n",
      " 1   path             2211 non-null   object\n",
      " 2   audio_base_path  2211 non-null   object\n",
      " 3   gold_transcript  2211 non-null   object\n",
      " 4   waveform_path    2211 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 86.5+ KB\n"
     ]
    }
   ],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>path</th>\n",
       "      <th>audio_base_path</th>\n",
       "      <th>gold_transcript</th>\n",
       "      <th>waveform_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>al_e026</td>\n",
       "      <td>samples/audio_processed/al_e026_A-02.wav</td>\n",
       "      <td>al_e026_A-02.wav</td>\n",
       "      <td>I do body. And I have a bag. Racking a... ......</td>\n",
       "      <td>samples/waveform/waveform_al_e026_A-02.wav.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>al_e026</td>\n",
       "      <td>samples/audio_processed/al_e026_A-03.wav</td>\n",
       "      <td>al_e026_A-03.wav</td>\n",
       "      <td>My body is a frog, frog, frog, cow, cow, cow,...</td>\n",
       "      <td>samples/waveform/waveform_al_e026_A-03.wav.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>al_e026</td>\n",
       "      <td>samples/audio_processed/al_e026_A-04.wav</td>\n",
       "      <td>al_e026_A-04.wav</td>\n",
       "      <td>A crack? It looks like a bag of people clicki...</td>\n",
       "      <td>samples/waveform/waveform_al_e026_A-04.wav.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>al_e026</td>\n",
       "      <td>samples/audio_processed/al_e026_A-05.wav</td>\n",
       "      <td>al_e026_A-05.wav</td>\n",
       "      <td>The broke, a broke croaking, cracked calf, cr...</td>\n",
       "      <td>samples/waveform/waveform_al_e026_A-05.wav.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>al_e026</td>\n",
       "      <td>samples/audio_processed/al_e026_A-06.wav</td>\n",
       "      <td>al_e026_A-06.wav</td>\n",
       "      <td>This is a frog calf. The two persons, Bok is ...</td>\n",
       "      <td>samples/waveform/waveform_al_e026_A-06.wav.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient                                      path   audio_base_path  \\\n",
       "0  al_e026  samples/audio_processed/al_e026_A-02.wav  al_e026_A-02.wav   \n",
       "1  al_e026  samples/audio_processed/al_e026_A-03.wav  al_e026_A-03.wav   \n",
       "2  al_e026  samples/audio_processed/al_e026_A-04.wav  al_e026_A-04.wav   \n",
       "3  al_e026  samples/audio_processed/al_e026_A-05.wav  al_e026_A-05.wav   \n",
       "4  al_e026  samples/audio_processed/al_e026_A-06.wav  al_e026_A-06.wav   \n",
       "\n",
       "                                     gold_transcript  \\\n",
       "0   I do body. And I have a bag. Racking a... ......   \n",
       "1   My body is a frog, frog, frog, cow, cow, cow,...   \n",
       "2   A crack? It looks like a bag of people clicki...   \n",
       "3   The broke, a broke croaking, cracked calf, cr...   \n",
       "4   This is a frog calf. The two persons, Bok is ...   \n",
       "\n",
       "                                    waveform_path  \n",
       "0  samples/waveform/waveform_al_e026_A-02.wav.npy  \n",
       "1  samples/waveform/waveform_al_e026_A-03.wav.npy  \n",
       "2  samples/waveform/waveform_al_e026_A-04.wav.npy  \n",
       "3  samples/waveform/waveform_al_e026_A-05.wav.npy  \n",
       "4  samples/waveform/waveform_al_e026_A-06.wav.npy  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['waveform_path'] = train_set.apply(lambda row: f\"samples/waveform/waveform_{row['audio_base_path']}.npy\", axis=1)\n",
    "val_set['waveform_path'] = val_set.apply(lambda row: f\"samples/waveform/waveform_{row['audio_base_path']}.npy\", axis=1)\n",
    "test_set['waveform_path'] = test_set.apply(lambda row: f\"samples/waveform/waveform_{row['audio_base_path']}.npy\", axis=1)\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def compute_audio_length(df: pd.DataFrame):\n",
    "    total_time = 0\n",
    "    for _, row in df.iterrows():\n",
    "        waveform = np.load(row['waveform_path'])\n",
    "        audio_time = librosa.get_duration(y=waveform, sr=16000)\n",
    "        total_time += audio_time\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set total audio time (hours): 15.1\n"
     ]
    }
   ],
   "source": [
    "total_time_train_hours = compute_audio_length(train_set) / 3600\n",
    "print(f\"Train set total audio time (hours): {total_time_train_hours:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set total audio time (hours): 3.2\n"
     ]
    }
   ],
   "source": [
    "total_time_val_hours = compute_audio_length(val_set) / 3600\n",
    "print(f\"Validation set total audio time (hours): {total_time_val_hours:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set total audio time (hours): 3.6\n"
     ]
    }
   ],
   "source": [
    "total_time_test_hours = compute_audio_length(test_set) / 3600\n",
    "print(f\"Test set total audio time (hours): {total_time_test_hours:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9422 entries, 0 to 9421\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   patient          9422 non-null   object\n",
      " 1   path             9422 non-null   object\n",
      " 2   audio_base_path  9422 non-null   object\n",
      " 3   gold_transcript  9422 non-null   object\n",
      " 4   waveform_path    9422 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 368.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2989\n",
      "11170\n"
     ]
    }
   ],
   "source": [
    "aphasic = []\n",
    "normal = []\n",
    "\n",
    "for audio in os.listdir('samples/audio'):\n",
    "    if 'al_' in audio:\n",
    "        aphasic.append(audio)\n",
    "    else:\n",
    "        normal.append(audio)\n",
    "\n",
    "print(len(aphasic))\n",
    "print(len(normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.3 hours\n",
      "14.9 hours\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "aphasic_wf = []\n",
    "normal_wf = []\n",
    "\n",
    "for wf in os.listdir('samples/waveform'):\n",
    "    if 'al_' in wf:\n",
    "        aphasic_wf.append(wf)\n",
    "    else:\n",
    "        normal_wf.append(wf)\n",
    "\n",
    "total_aphasic_seconds = 0\n",
    "total_normal_seconds = 0\n",
    "\n",
    "for wf in aphasic_wf:\n",
    "    wf = np.load(f'samples/waveform/{wf}')\n",
    "    total_aphasic_seconds += librosa.get_duration(y=wf, sr=16000)\n",
    "\n",
    "for wf in normal_wf:\n",
    "    wf = np.load(f'samples/waveform/{wf}')\n",
    "    total_normal_seconds += librosa.get_duration(y=wf, sr=16000)\n",
    "\n",
    "print(f\"{total_aphasic_seconds / (3600):.01f} hours\")\n",
    "print(f\"{total_normal_seconds / (3600):.01f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2047 entries, 0 to 2046\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   patient          2047 non-null   object\n",
      " 1   path             2047 non-null   object\n",
      " 2   audio_base_path  2047 non-null   object\n",
      " 3   gold_transcript  2047 non-null   object\n",
      " 4   waveform_path    2047 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 80.1+ KB\n"
     ]
    }
   ],
   "source": [
    "val_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['al_e026', 'al_e028', 'al_e078', 'al_e085', 'al_e099', 'al_e100',\n",
       "       'al_e101', 'al_e117', 'al_e118', 'al_e122', 'al_e132', 'al_e179',\n",
       "       'hl_e002', 'hl_e003', 'hl_e005', 'hl_e006', 'hl_e007', 'hl_e008',\n",
       "       'hl_e010', 'hl_e011', 'hl_e013', 'hl_e014', 'hl_e015', 'hl_e016',\n",
       "       'hl_e017', 'hl_e018', 'hl_e019', 'hl_e020', 'hl_e021', 'hl_e024',\n",
       "       'hl_e025', 'hl_e023', 'hl_e031', 'hl_e027', 'hl_e032', 'hl_e033',\n",
       "       'hl_e034', 'hl_e035', 'hl_e037', 'hl_e043', 'hl_e044', 'hl_e045',\n",
       "       'hl_e046', 'hl_e047', 'hl_e050', 'hl_e051', 'hl_e049', 'hl_e052',\n",
       "       'hl_e053', 'hl_e057', 'hl_e059', 'hl_e058', 'hl_e060', 'hl_e062',\n",
       "       'hl_e065', 'hl_e066', 'hl_e069', 'hl_e071', 'hl_e070', 'hl_e072'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['patient'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2211 entries, 0 to 2210\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   patient          2211 non-null   object\n",
      " 1   path             2211 non-null   object\n",
      " 2   audio_base_path  2211 non-null   object\n",
      " 3   gold_transcript  2211 non-null   object\n",
      " 4   waveform_path    2211 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 86.5+ KB\n"
     ]
    }
   ],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient                                                   al_e048\n",
       "path                     samples/audio_processed/al_e048_A-07.wav\n",
       "audio_base_path                                  al_e048_A-07.wav\n",
       "gold_transcript                                                 B\n",
       "waveform_path      samples/waveform/waveform_al_e048_A-07.wav.npy\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisper import log_mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>path</th>\n",
       "      <th>audio_base_path</th>\n",
       "      <th>gold_transcript</th>\n",
       "      <th>waveform_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>al_e026</td>\n",
       "      <td>samples/audio_processed/al_e026_A-02.wav</td>\n",
       "      <td>al_e026_A-02.wav</td>\n",
       "      <td>I do body. And I have a bag. Racking a... ......</td>\n",
       "      <td>samples/waveform/waveform_al_e026_A-02.wav.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>al_e026</td>\n",
       "      <td>samples/audio_processed/al_e026_A-03.wav</td>\n",
       "      <td>al_e026_A-03.wav</td>\n",
       "      <td>My body is a frog, frog, frog, cow, cow, cow,...</td>\n",
       "      <td>samples/waveform/waveform_al_e026_A-03.wav.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>al_e026</td>\n",
       "      <td>samples/audio_processed/al_e026_A-04.wav</td>\n",
       "      <td>al_e026_A-04.wav</td>\n",
       "      <td>A crack? It looks like a bag of people clicki...</td>\n",
       "      <td>samples/waveform/waveform_al_e026_A-04.wav.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>al_e026</td>\n",
       "      <td>samples/audio_processed/al_e026_A-05.wav</td>\n",
       "      <td>al_e026_A-05.wav</td>\n",
       "      <td>The broke, a broke croaking, cracked calf, cr...</td>\n",
       "      <td>samples/waveform/waveform_al_e026_A-05.wav.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>al_e026</td>\n",
       "      <td>samples/audio_processed/al_e026_A-06.wav</td>\n",
       "      <td>al_e026_A-06.wav</td>\n",
       "      <td>This is a frog calf. The two persons, Bok is ...</td>\n",
       "      <td>samples/waveform/waveform_al_e026_A-06.wav.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient                                      path   audio_base_path  \\\n",
       "0  al_e026  samples/audio_processed/al_e026_A-02.wav  al_e026_A-02.wav   \n",
       "1  al_e026  samples/audio_processed/al_e026_A-03.wav  al_e026_A-03.wav   \n",
       "2  al_e026  samples/audio_processed/al_e026_A-04.wav  al_e026_A-04.wav   \n",
       "3  al_e026  samples/audio_processed/al_e026_A-05.wav  al_e026_A-05.wav   \n",
       "4  al_e026  samples/audio_processed/al_e026_A-06.wav  al_e026_A-06.wav   \n",
       "\n",
       "                                     gold_transcript  \\\n",
       "0   I do body. And I have a bag. Racking a... ......   \n",
       "1   My body is a frog, frog, frog, cow, cow, cow,...   \n",
       "2   A crack? It looks like a bag of people clicki...   \n",
       "3   The broke, a broke croaking, cracked calf, cr...   \n",
       "4   This is a frog calf. The two persons, Bok is ...   \n",
       "\n",
       "                                    waveform_path  \n",
       "0  samples/waveform/waveform_al_e026_A-02.wav.npy  \n",
       "1  samples/waveform/waveform_al_e026_A-03.wav.npy  \n",
       "2  samples/waveform/waveform_al_e026_A-04.wav.npy  \n",
       "3  samples/waveform/waveform_al_e026_A-05.wav.npy  \n",
       "4  samples/waveform/waveform_al_e026_A-06.wav.npy  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiny.en',\n",
       " 'tiny',\n",
       " 'base.en',\n",
       " 'base',\n",
       " 'small.en',\n",
       " 'small',\n",
       " 'medium.en',\n",
       " 'medium',\n",
       " 'large-v1',\n",
       " 'large-v2',\n",
       " 'large-v3',\n",
       " 'large',\n",
       " 'large-v3-turbo',\n",
       " 'turbo']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "whisper.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from whisper import DecodingOptions\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "model = whisper.load_model('large-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:13.000]  Bride boy, you have a small little bride. She's a very pretty girl. She's a small boy.\n",
      "[00:13.000 --> 00:25.000]  She's been clicking her body and looking at her body when she's clicking small things.\n",
      "[00:00.000 --> 00:12.000]  Bright boy, you have a small little bright. She's a very pretty people. She's a small boy.\n",
      "[00:12.000 --> 00:25.000]  She's been clicking her body and looking at us, talking her body when she's clicking small things.\n",
      " Bride boy, you have a small little bride. She's a very pretty girl. She's a small boy. She's been clicking her body and looking at her body when she's clicking small things.\n",
      " Bright boy, you have a small little bright. She's a very pretty people. She's a small boy. She's been clicking her body and looking at us, talking her body when she's clicking small things.\n"
     ]
    }
   ],
   "source": [
    "res_temp0 = model.transcribe(\n",
    "    np.load(train_set['waveform_path'].iloc[55]),\n",
    "    verbose=True,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "res_temp03 = model.transcribe(\n",
    "    np.load(train_set['waveform_path'].iloc[55]),\n",
    "    verbose=True,\n",
    "    temperature=0.3,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "print(res_temp0['text'])\n",
    "print(res_temp03['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER for temp = 0.0: 5.555555555555555\n",
      "WER for temp = 0.3: 11.11111111111111\n"
     ]
    }
   ],
   "source": [
    "from jiwer import wer\n",
    "from whisper.normalizers import EnglishTextNormalizer\n",
    "\n",
    "normalizer = EnglishTextNormalizer()\n",
    "\n",
    "wer_temp_0 = wer(normalizer(train_set['gold_transcript'].iloc[55]), normalizer(res_temp0['text']))\n",
    "wer_temp_03 = wer(normalizer(train_set['gold_transcript'].iloc[55]), normalizer(res_temp03['text']))\n",
    "\n",
    "print(f\"WER for temp = 0.0: {wer_temp_0 * 100}\")\n",
    "print(f\"WER for temp = 0.3: {wer_temp_03 * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = log_mel_spectrogram(np.load(val_set['waveform_path'].iloc[0]))\n",
    "spec = np.pad(spec, ((0, 0), (0, 3000 - spec.shape[1])), mode='constant')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "spec = torch.tensor(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecodingResult(audio_features=tensor([[-1.1787,  1.7676, -0.6934,  ..., -0.4246, -0.9922,  0.3442],\n",
       "        [-0.8120,  2.2559, -0.1475,  ..., -0.3032, -0.8276,  0.2561],\n",
       "        [ 0.0821,  2.2441, -0.0927,  ..., -0.5024, -0.6113, -0.2166],\n",
       "        ...,\n",
       "        [-0.7119, -1.5713, -0.0238,  ...,  1.3818,  0.2429,  0.7856],\n",
       "        [-1.0498, -1.6338,  0.0679,  ...,  1.1738, -0.1987,  0.6753],\n",
       "        [-1.6641, -1.1670, -0.0039,  ...,  0.9429, -0.5078,  0.6011]],\n",
       "       dtype=torch.float16), language='en', language_probs=None, tokens=[50363, 347, 50463], text='B', avg_logprob=-0.7366571426391602, no_speech_prob=0.18790775537490845, temperature=0.0, compression_ratio=0.1111111111111111)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from whisper import DecodingOptions\n",
    "\n",
    "res = model.decode(\n",
    "    spec,\n",
    "    options=DecodingOptions(\n",
    "        task=\"transcribe\",\n",
    "        language=\"en\"\n",
    "    )\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecodingResult(audio_features=tensor([[-1.1787,  1.7676, -0.6934,  ..., -0.4246, -0.9922,  0.3442],\n",
       "        [-0.8120,  2.2559, -0.1475,  ..., -0.3032, -0.8276,  0.2561],\n",
       "        [ 0.0821,  2.2441, -0.0927,  ..., -0.5024, -0.6113, -0.2166],\n",
       "        ...,\n",
       "        [-0.7119, -1.5713, -0.0238,  ...,  1.3818,  0.2429,  0.7856],\n",
       "        [-1.0498, -1.6338,  0.0679,  ...,  1.1738, -0.1987,  0.6753],\n",
       "        [-1.6641, -1.1670, -0.0039,  ...,  0.9429, -0.5078,  0.6011]],\n",
       "       dtype=torch.float16), language='en', language_probs=None, tokens=[50363, 347, 50463], text='B', avg_logprob=-0.7366571426391602, no_speech_prob=0.18790775537490845, temperature=0.0, compression_ratio=0.1111111111111111)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
